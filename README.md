ABSTRACT:

Emotion recognition from EEG signals represents a promising frontier in understanding human 
affective states, with significant implications for mental health diagnostics, human-computer interaction, and the 
development of adaptive technologies. This research investigates the application of advanced machine learning 
techniques to classify emotional states derived from EEG data, utilizing both synthetic and real-world EEG 
signals. To facilitate this analysis, synthetic EEG signals that simulate various emotional states—such as 
happiness, sadness, anger, surprise, and neutrality—are generated. These signals incorporate frequency 
components typical of emotional responses, providing a robust basis for subsequent analysis. Feature extraction 
methods are employed to identify key patterns in the frequency domain, focusing on band power analysis and 
other relevant metrics that characterize emotional states. A combination of Convolutional Neural Networks 
(CNNs) and transfer learning is utilized to enhance classification accuracy. Specifically, the study leverages 
GoogLeNet, a well-established pre-trained model, which is fine-tuned to adapt to the unique features of EEG 
signals. This approach allows the model to benefit from the knowledge gained from extensive image datasets 
while effectively addressing the challenges posed by the limited availability of labelled EEG data. 
